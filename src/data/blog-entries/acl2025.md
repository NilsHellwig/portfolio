![At ACL 2025](/portfolio/blog-imgs/acl2025/acl2025-2.png)

This summer, I attended the **63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)** in Vienna, Austria. The conference offered a good opportunity to present our work, engage with other researchers, and learn about current developments in the NLP community.

![Workshop Schedule](/portfolio/blog-imgs/acl2025/acl2025-1.png)

## Presenting Our Work: Do We Still Need Human Annotators?

The highlight of my conference experience was presenting our poster on **["Do we still need Human Annotators? Prompting Large Language Models for Aspect Sentiment Quad Prediction"](https://aclanthology.org/2025.xllm-1.15/)** during the poster session. Our work explores whether large language models can reduce the need for extensive manual annotation in aspect-based sentiment analysis (ABSA) tasks.

![Our Poster](/portfolio/blog-imgs/acl2025/acl2025-3.png)

In this study, we investigated the capabilities of LLMs for zero- and few-shot learning on the ASQP task across five diverse datasets. The results were promising: in the 20-shot setting on the Rest16 restaurant domain dataset, LLMs achieved an F1 score of 51.54, compared to 60.39 by the best-performing fine-tuned method MVP. For the simpler TASD task, we got even closer to fine-tuned models, achieving 68.93 on Rest16 in the 30-shot setting, compared to 72.76 with MVP.

Our key finding: while human annotators remain essential for achieving optimal performance, LLMs can significantly reduce the need for extensive manual annotation in ASQP tasks. This is particularly valuable given how resource-intensive and time-consuming the annotation process is for complex ABSA tasks.

## Research from ACL 2025

Beyond presenting our own work, I had the chance to explore other research in NLP and ABSA. Two papers caught my attention in particular:

### [Personas with Attitudes: Controlling LLMs for Diverse Data Annotation](https://aclanthology.org/2025.woah-1.43/)

This workshop paper from WOAH 2025 by Fr√∂hling et al. introduces a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models. The authors inject diverse persona descriptions from the Persona Hub into LLM prompts to generate more diverse annotations.

What makes this interesting for my research is the potential to adapt this approach for low-resource ABSA scenarios. By combining personas with few-shot learning, we could generate more diverse training data for aspect-based sentiment analysis, especially in domains where annotated data is scarce.

The paper demonstrates that persona-prompted LLMs generate more diverse annotations than standard prompts and produce controllable effects that align with subjective differences in human annotations. This could be useful for creating synthetic training data in ABSA tasks.

### [BARTABSA++: Revisiting BARTABSA with Decoder LLMs](https://aclanthology.org/2025.xllm-1.13/)

Another standout paper from the **1st Joint Workshop on Large Language Models and Structure Modeling (XLLM 2025)** was BARTABSA++ by Pfister et al. . The XLLM workshop explores a critical question: Is NLP structure modeling still worth exploring in the LLM era? This paper perfectly addresses this question in the context of aspect-based sentiment analysis.

BARTABSA++ revisits the BARTABSA framework for aspect-based sentiment analysis with modern decoder LLMs to assess the importance of explicit structure modeling.

The findings show that BARTABSA++ with BART-LARGE achieves state-of-the-art results, even surpassing a finetuned GPT-4O model. The analysis reveals that the encoder's representational quality is vital, while the decoder's role is minimal. This explains the limited benefits of scaling decoder-only LLMs for ABSA tasks.

## Reflections and Future Directions

Attending ACL 2025 in Vienna confirmed that we're at an interesting point in NLP research. The integration of LLMs into traditional NLP pipelines, like ABSA, is not about replacement but augmentation. Human expertise, structured modeling, and the capabilities of large language models can work together to create more robust systems.

The connections between my work and the persona-based annotation approach I encountered at the conference have sparked new research ideas. I'm looking forward to exploring how we can combine these approaches to tackle low-resource ABSA scenarios more effectively.